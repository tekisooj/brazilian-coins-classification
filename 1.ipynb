{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2083ede3f70>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "torch.backends.cudnn.enDatasetable = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(image_name):\n",
    "    \"\"\"\n",
    "    Extracts the label from the image file name using a regex pattern.\n",
    "    \n",
    "    Args:\n",
    "        image_name (str): The name of the image file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted label (the number before the underscore in the file name).\n",
    "        None: If no match is found.\n",
    "    \"\"\"\n",
    "    match = re.match(r'(\\d+)_\\d+\\.jpg', image_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 550 2204 2204\n"
     ]
    }
   ],
   "source": [
    "def read_tar_to_array(file):\n",
    "    \"\"\"\n",
    "    Reads a tar file, extracts images, and converts them to arrays.\n",
    "    Extracts labels from file names and converts them to an array.\n",
    "    \n",
    "    Args:\n",
    "        file (str): Path to the tar file.\n",
    "        \n",
    "    Returns:\n",
    "        list of PIL.Image.Image: List of images in PIL format.\n",
    "        numpy.ndarray: Array of labels.\n",
    "    \"\"\"\n",
    "    # Open the tar file\n",
    "    tar = tarfile.open(file, \"r:xz\")\n",
    "    \n",
    "    # Lists to store images and labels\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    # Iterate over the tar file\n",
    "    for tarinfo in tar:\n",
    "        tar.extract(tarinfo.name)  # Extract the file from the tar archive\n",
    "        if tarinfo.name.endswith('.jpg'):  # Check if the file is a JPEG image\n",
    "            # Open the image file and convert it to RGB format \n",
    "            image_list.append(Image.open(tarinfo.name).convert(\"RGB\"))\n",
    "            # Extract the label from the file name and append it to label_list\n",
    "            label_list.append(tarinfo.name.split('_/')[1])\n",
    "                              \n",
    "    # Close the tar file\n",
    "    tar.close()\n",
    "    \n",
    "    # Extract labels and convert to numpy array\n",
    "    labels = np.array([i.split('_', 1)[0] for i in label_list])\n",
    "    \n",
    "    return image_list, labels\n",
    "\n",
    "# Convert tar archive files into PIL objects and extract labels\n",
    "test_img, test_labels = read_tar_to_array(test_tar)\n",
    "train_img, train_labels = read_tar_to_array(train_tar)\n",
    "\n",
    "# Check the length of the training and test datasets\n",
    "print(len(test_img), len(test_labels), len(train_img), len(train_labels))\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_img, val_img, train_labels, val_labels = train_test_split(\n",
    "    train_img, train_labels, test_size=0.2, random_state=random_seed\n",
    ")\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image or numpy array to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize with mean and std for each channel\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrazillianCoins(Dataset):\n",
    "    def __init__(self, files, labels):\n",
    "        \"\"\"\n",
    "        Dataset class for images. Transforms images (resizing, grayscale conversion,\n",
    "        tensor conversion, and normalization) and prepares them for input into a CNN.\n",
    "        \n",
    "        Args:\n",
    "            files (list of PIL.Image.Image): List of image objects.\n",
    "            labels (list of str): List of labels corresponding to the images.\n",
    "        \"\"\"\n",
    "        # Define the transformations: Resize, convert to grayscale, convert to tensor, and normalize\n",
    "        self.transforms = T.Compose([\n",
    "            T.Resize((128, 128)),          # Resize images to 128x128 pixels\n",
    "            T.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "            T.ToTensor(),                  # Convert PIL images to PyTorch tensors\n",
    "            T.Normalize((0.5,), (0.5,))   # Normalize the images with mean and std for grayscale\n",
    "        ])\n",
    "        self.files = files                # Store the list of image objects\n",
    "        self.labels = labels              # Store the list of labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve an image and its label at the specified index, apply transformations,\n",
    "        and return the processed image and its label.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the item to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (transformed_image, label) where `transformed_image` is a tensor \n",
    "                   and `label` is an integer class label.\n",
    "        \"\"\"\n",
    "        # Dictionary to convert string labels to integers\n",
    "        class_dict = {'5': 0, '10': 1, '25': 2, '50': 3, '100': 4}\n",
    "        \n",
    "        file = self.files[idx]            # Get the image at the specified index\n",
    "        img = self.transforms(file)       # Apply transformations to the image\n",
    "        label = class_dict[self.labels[idx]]  # Convert the label to an integer\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of images in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            int: Number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataset objects for training, testing, and validation\n",
    "train_tensor = BrazillianCoins(train_img, train_labels)\n",
    "val_tensor = BrazillianCoins(val_img, val_labels)\n",
    "test_tensor = BrazillianCoins(test_img, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 1763)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tensor), len(train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size for data loading\n",
    "batch_size = 128\n",
    "\n",
    "# Load data into PyTorch DataLoader for batching and shuffling\n",
    "train_loader = DataLoader(train_tensor, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_tensor, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create dictionaries to store loaders and dataset sizes for easy access\n",
    "loaders = {'train': train_loader, 'test': test_loader}\n",
    "sizes = {'train': len(train_tensor), 'test': len(test_tensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrazilianCoinConvClassifier(nn.Module):\n",
    "    def __init__(self, number_of_classes):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional neural network model for image classification.\n",
    "        \n",
    "        Args:\n",
    "            number_of_classes (int): Number of output classes for classification.\n",
    "        \"\"\"\n",
    "        super(BrazilianCoinConvClassifier, self).__init__()\n",
    "        \n",
    "        # Define the layers of the neural network\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)          # Dropout layer to prevent overfitting\n",
    "        self.dropout2 = nn.Dropout(0.5)           # Another dropout layer with higher dropout rate\n",
    "        self.fc1 = nn.Linear(in_features=246016, out_features=128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=number_of_classes)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the model, applying convolutional layers, activation functions,\n",
    "        pooling, dropout, and fully connected layers.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor (batch of images).\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)               # Apply first convolutional layer\n",
    "        x = F.relu(x)                   # Apply ReLU activation function\n",
    "        x = self.conv2(x)               # Apply second convolutional layer\n",
    "        x = F.relu(x)                   # Apply ReLU activation function\n",
    "        x = F.max_pool2d(input=x, kernel_size=2)  # Apply max pooling with 2x2 kernel\n",
    "        x = self.dropout1(x)            # Apply dropout to reduce overfitting\n",
    "\n",
    "        x = torch.flatten(x, 1)         # Flatten the tensor for fully connected layers\n",
    "        x = self.fc1(x)                 # Apply first fully connected layer\n",
    "        x = F.relu(x)                   # Apply ReLU activation function\n",
    "        x = self.dropout2(x)            # Apply dropout to reduce overfitting\n",
    "        x = self.fc2(x)                 # Apply output fully connected layer\n",
    "        output = F.log_softmax(x, dim=1)  # Apply log softmax activation function\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the device to be used for tensor computations.\n",
    "    Checks if CUDA (GPU) is available, otherwise defaults to CPU.\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The device to be used (either \"cuda\" or \"cpu\").\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def bind_gpu(data):\n",
    "    \"\"\"\n",
    "    Move the given data to the appropriate device (GPU or CPU).\n",
    "    Handles both single tensors and collections (lists or tuples) of tensors.\n",
    "    \n",
    "    Args:\n",
    "        data (Tensor or list of Tensors): Data to move to the device.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor or list of Tensors: Data moved to the device.\n",
    "    \"\"\"\n",
    "    device = get_device()\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        # Recursively move each element in the list or tuple to the device\n",
    "        return [bind_gpu(data_elem) for data_elem in data]\n",
    "    else:\n",
    "        # Move the tensor to the device\n",
    "        return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrazilianCoinConvClassifier(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=246016, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 5\n",
    "# Initialize the model with the specified number of output classes\n",
    "model = BrazilianCoinConvClassifier(number_of_classes)\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "bind_gpu(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count the total number of parameters in the model and print details for each layer.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model whose parameters are to be counted.\n",
    "    \n",
    "    Returns:\n",
    "        int: Total number of parameters in the model.\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())  # Total parameter count\n",
    "\n",
    "    # Iterate through the layers of the model and print parameter details\n",
    "    for name, layer in model.named_children():\n",
    "        num_params = sum(p.numel() for p in layer.parameters())\n",
    "        print(f\"Layer: {name}, Parameters: {num_params}\")\n",
    "\n",
    "    return total_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1, Parameters: 320\n",
      "Layer: conv2, Parameters: 18496\n",
      "Layer: dropout1, Parameters: 0\n",
      "Layer: dropout2, Parameters: 0\n",
      "Layer: fc1, Parameters: 31490176\n",
      "Layer: fc2, Parameters: 645\n",
      "Total Parameters: 31509637\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of parameters in the model and details for each layer\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification(model, criterion, optimizer, number_of_epochs, train_loader, validation_loader):\n",
    "    \"\"\"\n",
    "    Train the classification model using the provided data loader, loss function, and optimizer.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to be trained.\n",
    "        criterion (nn.Module): The loss function used for training.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "        number_of_epochs (int): Number of epochs to train the model.\n",
    "        train_loader (DataLoader): DataLoader providing the training data.\n",
    "        multiclass (bool): Indicates if the task is multiclass classification (default is False).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (losses, accuracies) where losses is a list of loss values for each epoch\n",
    "               and accuracies is a list of accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    device = get_device()  # Get the device to be used for training\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{number_of_epochs}]\")\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        model.train()  # Set the model to training mode\n",
    "    \n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            # Move inputs and labels to the appropriate device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass: Compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            \n",
    "            # Backward pass: Compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct_train += (predicted.squeeze() == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        # Compute average loss and accuracy for this epoch\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "        \n",
    "        # Append the loss and accuracy for this epoch to the lists\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        \n",
    "        # Validation phase\n",
    "        valid_loss = 0.0\n",
    "        correct_valid = 0\n",
    "        total_valid = 0\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "                # Compute loss\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                predicted = torch.max(outputs, dim1)\n",
    "                correct_valid += (predicted.squeeze() == labels).sum().item()\n",
    "                total_valid += labels.size(0)\n",
    "\n",
    "        valid_accuracy = correct_valid / total_valid\n",
    "        valid_losses.append(valid_loss / len(validation_loader))\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "        # Print the results\n",
    "        print(f'Accuracy: train {train_accuracy:.4f} \\t validation : {valid_accuracy:.4f}')\n",
    "        print(f'Loss: train {train_loss:.4f} \\t validation : {valid_loss:.4f}')\n",
    "\n",
    "\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs for training\n",
    "N_EPOCHS = 30\n",
    "\n",
    "# Define the loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Used for classification problems with multiple classes\n",
    "optimizer = optim.Adam(model.parameters())  # Adam optimizer for updating model parameters\n",
    "\n",
    "# Train the model and get the losses and accuracies for training and validation\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train_classification(\n",
    "    model, criterion, optimizer, N_EPOCHS, train_loader, val_loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification(loss, accuracy, loss_title='Training Loss', accuracy_title='Training Accuracy'):\n",
    "    \"\"\"\n",
    "    Plot training loss and accuracy over epochs.\n",
    "    \n",
    "    Args:\n",
    "        loss (list): List of loss values for each epoch.\n",
    "        accuracy (list): List of accuracy values for each epoch.\n",
    "        loss_title (str): Title of the loss plot.\n",
    "        accuracy_title (str): Title of the accuracy plot.\n",
    "    \"\"\"\n",
    "    number_of_epochs = len(loss)  # Number of epochs is the length of the loss list\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.title(loss_title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(range(number_of_epochs), loss, label='Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training accuracy\n",
    "    plt.title(accuracy_title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(range(number_of_epochs), accuracy, label='Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss and accuracy\n",
    "plot_classification(train_losses, train_accuracies, 'Training Loss', 'Training Accuracy')\n",
    "plot_classification(val_losses, val_accuracies, 'Validation Loss', 'Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(model, criterion, loader, multiclass=False):\n",
    "    \"\"\"\n",
    "    Evaluate the classification model on a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to be evaluated.\n",
    "        criterion (nn.Module): The loss function used for evaluation.\n",
    "        loader (DataLoader): DataLoader providing the evaluation data.\n",
    "        multiclass (bool): Indicates if the task is multiclass classification (default is False).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (avg_loss, accuracy) where avg_loss is the average loss and accuracy is the accuracy of the model.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0  # Accumulate total loss\n",
    "    total_correct = 0  # Accumulate number of correct predictions\n",
    "    total_samples = 0  # Total number of samples processed\n",
    "    predicted_labels, true_labels = [], []  # Lists to store predicted and true labels\n",
    "    device = get_device()  # Get the device to be used (CPU or GPU)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "        for inputs, labels in loader:\n",
    "            # Move inputs and labels to the appropriate device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Perform forward pass to get model outputs\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute and accumulate loss\n",
    "            total_loss += criterion(outputs.squeeze(), labels).item()\n",
    "\n",
    "            # Make predictions based on the outputs\n",
    "            if multiclass:\n",
    "                # For multiclass classification, use argmax to get the predicted class\n",
    "                predicted = torch.argmax(outputs, dim=1)\n",
    "            else:\n",
    "                # For binary classification, threshold the outputs to get predictions\n",
    "                predicted = (outputs > 0.5).float()\n",
    "            \n",
    "            # Collect predicted and true labels for metrics calculation\n",
    "            predicted_labels.extend(predicted.squeeze().tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted.squeeze() == labels).sum().item()\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f'Model evaluation on: {loader}')\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the training set and print results\n",
    "train_loss, train_accuracy = evaluate_classification(model, criterion, train_loader, multiclass=True)\n",
    "print(f'Train Set: Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set and print results\n",
    "test_loss, test_accuracy = evaluate_classification(model, criterion, test_loader, multiclass=True)\n",
    "print(f'Test Set: Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Saves the model's state_dict to the specified file path.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to save.\n",
    "        filepath (str): The path where the model will be saved.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(model_class, filepath, number_of_classes):\n",
    "    \"\"\"\n",
    "    Loads the model's state_dict from the specified file path into a new model instance.\n",
    "    \n",
    "    Args:\n",
    "        model_class (type): The class of the model to load.\n",
    "        filepath (str): The path where the model's state_dict is stored.\n",
    "        number_of_classes (int): Number of output classes for the model.\n",
    "    \n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded model with weights.\n",
    "    \"\"\"\n",
    "    model = model_class(number_of_classes)  # Create a new instance of the model class\n",
    "    model.load_state_dict(torch.load(filepath))  # Load the state dict into the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
